{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from Config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names():\n",
    "    files = [f for f in glob.glob(CSV_DATA_PATH+\"*.csv\")]\n",
    "    file_list = []\n",
    "    for file in files:\n",
    "        file_list.append(file)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_to_hd():\n",
    "    filenames = get_file_names()\n",
    "    main_df = pd.DataFrame()\n",
    "    for i in filenames:\n",
    "        df = pd.read_csv(i)\n",
    "        df['text'] = df['text'].apply(str) \n",
    "        main_df = pd.concat([main_df , df], ignore_index=True)\n",
    "    if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        os.mkdir(PROCESSED_DATA_PATH)\n",
    "    main_df.to_hdf(PROCESSED_DATA_PATH + RAW_DATA, key='raw', append=True, format='t', min_itemsize={'text': 4096})\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(line):\n",
    "    # Converting to lower\n",
    "    line = line.lower()\n",
    "\n",
    "    # Removing alphanumerics\n",
    "    tokens = [word for word in line.split() if word.isalpha()]\n",
    "\n",
    "    # Removing Punctuations\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    tokens = [word.translate(translator) for word in tokens]\n",
    "\n",
    "    # Removing stop_words\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # tokens = [word for word in tokens if not word in stop_words]\n",
    "\n",
    "    # Removing short_words\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/tables/leaf.py:414: PerformanceWarning: The Leaf ``/raw/_i_table/text/sorted`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  PerformanceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/generic.py:2530: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['file', 'label', 'text']]\n",
      "\n",
      "  pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "process_raw_to_hd()\n",
    "df = pd.read_hdf(PROCESSED_DATA_PATH + RAW_DATA)\n",
    "df = df.dropna()\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df = df.dropna()\n",
    "df.to_hdf(PROCESSED_DATA_PATH + CLEAN_DATA, key='clean')\n",
    "df = pd.read_hdf(PROCESSED_DATA_PATH + CLEAN_DATA,key='clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_sentences_ug(sent,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(sent.index, sent):\n",
    "        result.append(TaggedDocument(t, [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = df.text\n",
    "all_x_w2v = labelize_sentences_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2527705.39it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_cbow = Word2Vec(sg=0, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_cbow.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2489435.73it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2613710.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2633694.11it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2619560.02it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2585892.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2622715.89it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2682965.11it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2640402.12it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2498521.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2619244.85it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2674329.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2547284.88it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2596750.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2660732.76it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2553858.98it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2613773.02it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2420623.05it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2515961.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2569776.13it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2577137.99it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2606762.40it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2698328.64it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2609512.08it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2651141.74it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2506633.91it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2609011.71it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2682105.69it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2621705.18it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2576649.96it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2738723.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 213 ms, total: 18.5 s\n",
      "Wall time: 5.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_cbow.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_cbow.alpha -= 0.002\n",
    "    model_ug_cbow.min_alpha = model_ug_cbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2437699.09it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ug_sg = Word2Vec(sg=1, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_sg.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2481547.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2593162.22it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2616411.73it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2179539.81it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2681048.70it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2511260.29it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2623284.75it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2546808.08it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2591063.49it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2605140.31it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2600161.89it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2547582.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2608261.51it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2565717.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2660862.85it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2679860.59it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2647530.71it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2586384.48it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2503347.99it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2498750.69it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2667514.03it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2524012.83it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2582518.62it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2632356.59it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2627020.09it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2573786.47it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2698863.87it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2534119.70it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2580742.98it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 25952/25952 [00:00<00:00, 2541041.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.5 s, sys: 309 ms, total: 43.8 s\n",
      "Wall time: 7.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_sg.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_sg.alpha -= 0.002\n",
    "    model_ug_sg.min_alpha = model_ug_sg.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ug_cbow.save('w2v_model_ug_cbow.word2vec')\n",
    "model_ug_sg.save('w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_ug_cbow = KeyedVectors.load('w2v_model_ug_cbow.word2vec')\n",
    "model_ug_sg = KeyedVectors.load('w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_ug_cbow.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
