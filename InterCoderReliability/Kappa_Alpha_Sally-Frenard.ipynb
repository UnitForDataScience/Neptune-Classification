{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 8 columns):\n",
      "Coders             0 non-null object\n",
      "#Similar           0 non-null object\n",
      "#Dissimilar        0 non-null object\n",
      "#Total             0 non-null object\n",
      "Kappa_Score        0 non-null object\n",
      "Kappa_Agreement    0 non-null object\n",
      "Alpha_Score        0 non-null object\n",
      "Alpha_Agreement    0 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_kappa_alpha = pd.DataFrame(columns=['Coders','#Similar','#Dissimilar','#Total','Kappa_Score','Kappa_Agreement','Alpha_Score','Alpha_Agreement'])\n",
    "df_kappa_alpha.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_score(label1, label2, dir):\n",
    "    files = [f for f in glob.glob(dir)]\n",
    "    \n",
    "    same = 0\n",
    "    diff = 0\n",
    "    label_dic1 = {'T':0, 'P':0, 'O':0, 'D': 0, 'H':0, 'U':0}\n",
    "    label_dic2 = {'T':0, 'P':0, 'O':0, 'D': 0, 'H':0, 'U':0}\n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df = df.replace(np.nan, '', regex=True)\n",
    "        \n",
    "        for i in range(len(df['text'])):\n",
    "            if df['file'][i]=='':\n",
    "                break\n",
    "            if df[label1][i]==df[label2][i] and df[label1][i] == 'U':\n",
    "                continue\n",
    "            if len(df[label2])==0 and df[label1][i] == 'U':\n",
    "                continue\n",
    "            if len(df[label1])==0 and df[label2][i] == 'U':\n",
    "                continue\n",
    "\n",
    "            label_1 = str(df[label1][i]).replace(\" \", \"\")\n",
    "            label_1 = label_1.split(',')[0]\n",
    "            if len(label_1)>0:\n",
    "                label_dic1[label_1]+=1\n",
    "\n",
    "            label_2 = str(df[label2][i]).replace(\" \", \"\")\n",
    "            label_2 = label_2.split(',')[0]\n",
    "            if len(label_2)>0:\n",
    "                label_dic2[label_2]+=1\n",
    "\n",
    "            if label_1==label_2:\n",
    "                same+=1\n",
    "            else:\n",
    "                diff+=1\n",
    "                \n",
    "    po=same/(same+diff)\n",
    "    for k in label_dic1:\n",
    "        label_dic1[k]=label_dic1[k]/(same+diff)\n",
    "        \n",
    "    for k in label_dic2:\n",
    "        label_dic2[k]=label_dic2[k]/(same+diff)\n",
    "        \n",
    "    label_prob = {'T':0, 'P':0, 'O':0, 'D': 0, 'H':0, 'U':0}\n",
    "    \n",
    "    for k in label_prob:\n",
    "        label_prob[k] = label_dic1[k]*label_dic2[k]\n",
    "        \n",
    "    pe = 0\n",
    "    for k in label_prob:\n",
    "        pe += label_prob[k]\n",
    "    \n",
    "    kappa = (po-pe)/(1-pe)\n",
    "    \n",
    "    if kappa<0.1:\n",
    "        kappa_agreement = 'No'\n",
    "    elif kappa>=0.1 and kappa<0.2:\n",
    "        kappa_agreement =   'Slight'\n",
    "    elif kappa>=0.2 and kappa<0.4:\n",
    "        kappa_agreement = 'Fair'\n",
    "    elif kappa>=0.4 and kappa<0.6:\n",
    "        kappa_agreement = 'Moderate'\n",
    "    elif kappa>=0.6 and kappa<0.8:\n",
    "        kappa_agreement = 'Substatial'\n",
    "    elif kappa>=0.8 and kappa<1:\n",
    "        kappa_agreement = 'Near Perfect'    \n",
    "    elif kappa==1:\n",
    "        kappa_agreement = 'Perfect'\n",
    "    \n",
    "    total = same+diff\n",
    "    \n",
    "    return same, diff, total, kappa, kappa_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_without_u = {'T':1, 'P':2, 'O':3, 'D': 4, 'H':5, 'U':np.nan}\n",
    "def key_to_value_ignoring_u(key):\n",
    "    if type(key) == float:\n",
    "        return np.nan\n",
    "    key = key.strip()\n",
    "    key.split(',')\n",
    "    key = key[0]\n",
    "    return labels_without_u[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def krippendorff_alpha(filter_key, label1, label2, dir):\n",
    "    files = [f for f in glob.glob(dir)]\n",
    "    \n",
    "    label_1 = []\n",
    "    label_2 = []\n",
    "    \n",
    "    rel_mat = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df[label2] = df[label2].apply(filter_key)\n",
    "        df[label1] = df[label1].apply(filter_key)\n",
    "        \n",
    "        label_1.extend(df[label1])\n",
    "        label_2.extend(df[label2])\n",
    "        \n",
    "    reliability_matrix = np.asarray([label_1,label_2])\n",
    "        \n",
    "    alpha = krippendorff.alpha(reliability_matrix[[0,1]])\n",
    "    \n",
    "    if alpha<0.1:\n",
    "        alpha_agreement = 'No'\n",
    "    elif alpha>=0.1 and alpha<0.2:\n",
    "        alpha_agreement =   'Slight'\n",
    "    elif alpha>=0.2 and alpha<0.4:\n",
    "        alpha_agreement = 'Fair'\n",
    "    elif alpha>=0.4 and alpha<0.6:\n",
    "        alpha_agreement = 'Moderate'\n",
    "    elif alpha>=0.6 and alpha<0.8:\n",
    "        alpha_agreement = 'Substatial'\n",
    "    elif alpha>=0.8 and alpha<1:\n",
    "        alpha_agreement = 'Near Perfect'    \n",
    "    elif alpha==1:\n",
    "        alpha_agreement = 'Perfect'\n",
    "    \n",
    "    return alpha, alpha_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coders = []\n",
    "similars = []\n",
    "dissimilars = []\n",
    "totals = []\n",
    "kappas = []\n",
    "kappas_agrees = []\n",
    "alphas = []\n",
    "alphas_agrees = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = \"Sally_Frenard\"\n",
    "same, diff, total, kappa, kappa_agree = kappa_score('label_Frenard', 'label_SALLY', \"MergedFiles-SALLY-Frenard/*.csv\")\n",
    "alpha, alpha_agree = krippendorff_alpha(key_to_value_ignoring_u, 'label_Frenard', 'label_SALLY', \"MergedFiles-SALLY-Frenard/*.csv\")\n",
    "\n",
    "coders.append(coder)\n",
    "similars.append(same)\n",
    "dissimilars.append(diff)\n",
    "totals.append(total)\n",
    "kappas.append(kappa)\n",
    "kappas_agrees.append(kappa_agree)\n",
    "alphas.append(alpha)\n",
    "alphas_agrees.append(alpha_agree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = \"Sally_Trixy\"\n",
    "same, diff, total, kappa, kappa_agree = kappa_score('label_struck', 'label_SALLY', \"MergedFiles-SALLY-struck/*.csv\")\n",
    "alpha, alpha_agree = krippendorff_alpha(key_to_value_ignoring_u, 'label_struck', 'label_SALLY', \"MergedFiles-SALLY-struck/*.csv\")\n",
    "\n",
    "coders.append(coder)\n",
    "similars.append(same)\n",
    "dissimilars.append(diff)\n",
    "totals.append(total)\n",
    "kappas.append(kappa)\n",
    "kappas_agrees.append(kappa_agree)\n",
    "alphas.append(alpha)\n",
    "alphas_agrees.append(alpha_agree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kappa_alpha['Coders']= coders\n",
    "df_kappa_alpha['#Similar'] = similars\n",
    "df_kappa_alpha['#Dissimilar'] = dissimilars\n",
    "df_kappa_alpha['#Total'] = totals\n",
    "df_kappa_alpha['Kappa_Score'] = kappas\n",
    "df_kappa_alpha['Kappa_Agreement'] = kappas_agrees\n",
    "df_kappa_alpha['Alpha_Score'] = alphas\n",
    "df_kappa_alpha['Alpha_Agreement'] = alphas_agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coders</th>\n",
       "      <th>#Similar</th>\n",
       "      <th>#Dissimilar</th>\n",
       "      <th>#Total</th>\n",
       "      <th>Kappa_Score</th>\n",
       "      <th>Kappa_Agreement</th>\n",
       "      <th>Alpha_Score</th>\n",
       "      <th>Alpha_Agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sally_Frenard</td>\n",
       "      <td>70</td>\n",
       "      <td>166</td>\n",
       "      <td>236</td>\n",
       "      <td>0.064409</td>\n",
       "      <td>No</td>\n",
       "      <td>0.429068</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sally_Trixy</td>\n",
       "      <td>49</td>\n",
       "      <td>155</td>\n",
       "      <td>204</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>No</td>\n",
       "      <td>0.491475</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coders  #Similar  #Dissimilar  #Total  Kappa_Score Kappa_Agreement  \\\n",
       "0  Sally_Frenard        70          166     236     0.064409              No   \n",
       "1    Sally_Trixy        49          155     204     0.092813              No   \n",
       "\n",
       "   Alpha_Score Alpha_Agreement  \n",
       "0     0.429068        Moderate  \n",
       "1     0.491475        Moderate  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kappa_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kappa_alpha.to_csv('Results/Overall_Results.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
