{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_binary.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCWEo/GRyn8cE/oiDxHcqf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kU4rkhyU8W1F","colab_type":"text"},"source":["#BInary-Class Classification using BERT"]},{"cell_type":"markdown","metadata":{"id":"wnqXrY1E8l-g","colab_type":"text"},"source":["Classifying the sentences from IRs (Instruction Reports) into Useless and Usefull Sentences: <Br>\n","U: Useless <br>\n","N: Non Useless <br>\n","\n","<br>\n","For Training Data, we have sentences labelled by Sally"]},{"cell_type":"markdown","metadata":{"id":"hpbefIXC9JZD","colab_type":"text"},"source":["## 1. Configuring GPU and Libraries"]},{"cell_type":"code","metadata":{"id":"ZXUBktv22Eub","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":81},"outputId":"a1450725-6101-4fa1-d6f4-fb8e2b4d6fdd","executionInfo":{"status":"ok","timestamp":1581401513743,"user_tz":420,"elapsed":2127,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["# verify GPU availability\n","import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wz45ngag3eTn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":266},"outputId":"293ea9a9-9545-4874-a723-378f745ffd46","executionInfo":{"status":"ok","timestamp":1581399754838,"user_tz":420,"elapsed":10819,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=9f4af614b1047f462ccdceee250dc19be2b3b3a113f2dcbc681bf3d577ac67ee\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.6 GB  | Proc size: 500.1 MB\n","GPU RAM Free: 14968MB | Used: 111MB | Util   1% | Total 15079MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J03mnzNB3g_Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"bafce6ee-d0ae-4cee-b025-3be53e040b03","executionInfo":{"status":"ok","timestamp":1581401522011,"user_tz":420,"elapsed":1351,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["!ps ax | grep python"],"execution_count":2,"outputs":[{"output_type":"stream","text":["     23 ?        Sl     0:04 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --MappingKernelManager.root_dir=\"/content\"\n","   1191 ?        Ssl    0:02 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-008fd001-51d5-414b-b990-1ac9561028bb.json\n","   1245 ?        S      0:00 /bin/bash -c ps ax | grep python\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XJClXvmB3iEF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":354},"outputId":"a929e762-7a4f-4bb7-9fd2-7f8950478249","executionInfo":{"status":"ok","timestamp":1581401528025,"user_tz":420,"elapsed":3175,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["!pip install pytorch-pretrained-bert pytorch-nlp"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n","Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.10)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.2)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.10)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->pytorch-pretrained-bert) (2.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.10->boto3->pytorch-pretrained-bert) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vxNP55op3nid","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"2e640309-c2a3-4670-b09e-8f06d8d12d12","executionInfo":{"status":"ok","timestamp":1581401533904,"user_tz":420,"elapsed":1662,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["# BERT imports\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import string\n","import os\n","import glob\n","% matplotlib inline\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"AA5uLrLy3qhn","colab_type":"code","colab":{}},"source":["torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mc9SLdWA3tuD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3c3dd762-81d5-4668-9473-8c99e1a05dce","executionInfo":{"status":"ok","timestamp":1581401537725,"user_tz":420,"elapsed":467,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["from google.colab import drive\n","drive.mount(\"/GD\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /GD; to attempt to forcibly remount, call drive.mount(\"/GD\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MY-WrK-i3vxQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"17c78a6d-6c0d-41ba-aa9a-aa8dd20f22e9","executionInfo":{"status":"ok","timestamp":1581401541109,"user_tz":420,"elapsed":509,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","print(\"tensorflow version : \", tf.__version__)\n","print(\"tensorflow_hub version : \", hub.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensorflow version :  1.15.0\n","tensorflow_hub version :  0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Snmh9JT30nB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"86576c91-a5b0-472a-8e07-8ea8eb48b47d","executionInfo":{"status":"ok","timestamp":1581401545991,"user_tz":420,"elapsed":2814,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["\n","#Installing BERT module\n","!pip install bert-tensorflow"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X8f_jEzr31ri","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"32d60f49-781b-4525-f207-df0aa64c6199","executionInfo":{"status":"ok","timestamp":1581401550385,"user_tz":420,"elapsed":384,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["\n","#Importing BERT modules\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l4Geh-pc34uh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"88ff2b44-f515-4524-8e81-c331ff87d9b7","executionInfo":{"status":"ok","timestamp":1581401553548,"user_tz":420,"elapsed":406,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["OUTPUT_DIR = '/GD/My Drive/Colab Notebooks/DS_Lab/Models1'\n","\n","#@markdown Whether or not to clear/delete the directory and create a new one\n","DO_DELETE = True #@param {type:\"boolean\"}\n","\n","if DO_DELETE:\n","  try:\n","    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n","  except:\n","    pass\n","\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["***** Model output directory: /GD/My Drive/Colab Notebooks/DS_Lab/Models1 *****\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7a1H48qn9PfP","colab_type":"text"},"source":["## 2. Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"KnG4XWGd38_W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ba2f3901-8d64-4e01-fe5c-a1c7b46545d8","executionInfo":{"status":"ok","timestamp":1581401557066,"user_tz":420,"elapsed":641,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["files = [f for f in glob.glob(\"*.csv\")]\n","df_raw = pd.DataFrame()\n","\n","for file in files:\n"," \n","  df = pd.read_csv(file)\n","  df['text'] = df['text'].apply(str)\n","  df_raw = pd.concat([df_raw , df], ignore_index=True)\n","\n","df = df_raw.dropna()\n","\n","count_usefull = 0\n","for label in df['label_SALLY']:\n","    if label != 'U':\n","        count_usefull += 1\n","print(\"No. of Usefull Sentences: \" + str(count_usefull))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["No. of Usefull Sentences: 317\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q5meAuEW9YFB","colab_type":"text"},"source":["In order to have unbiased classification, we are cosidering equal no. of useless and non usefull sentences as the Training Data"]},{"cell_type":"code","metadata":{"id":"sCtxvZDZ5gH_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":140},"outputId":"ad7017eb-4fe7-4ebc-d7c3-cd21d0b81a1a","executionInfo":{"status":"ok","timestamp":1581401560172,"user_tz":420,"elapsed":627,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["def class_label_handler_binarysentenceclassifier(class_label):\n","  global count_usefull\n","  if class_label == 'U':\n","      count_usefull -= 1\n","      if count_usefull < 0:\n","          return np.NaN\n","  return class_label\n","  \n","df['Y'] = df['label_SALLY'].apply(class_label_handler_binarysentenceclassifier)\n","df = df.dropna()\n","df['Y'] = df['Y'].apply(lambda v: 0 if v == \"U\" else 1)\n","len(df['Y'])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["634"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"EJZf_LVG6XS4","colab_type":"code","colab":{}},"source":["# Splitting Training and Test\n","TRAIN_TEST_SPLIT = 0.8\n","msk = np.random.rand(len(df)) < TRAIN_TEST_SPLIT\n","df_train = df[msk]\n","df_test = df[~msk]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KNsDLqJ6aYi","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","train, val =  train_test_split(df_train, test_size = 0.2, random_state = 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Unlad3q46bP2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"43ff4f9b-c612-41d5-ac22-4874ce23aed7","executionInfo":{"status":"ok","timestamp":1581401568543,"user_tz":420,"elapsed":565,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["print(\"Training Set Shape :\", train.shape)\n","print(\"Validation Set Shape :\", val.shape)\n","print(\"Test Set Shape :\", df_test.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Training Set Shape : (389, 7)\n","Validation Set Shape : (98, 7)\n","Test Set Shape : (147, 7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QFVNY9Xb6gUz","colab_type":"code","colab":{}},"source":["DATA_COLUMN = 'text'\n","LABEL_COLUMN = 'Y'\n","# The list containing all the classes (train['SECTION'].unique())\n","label_list = [0, 1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Pr4bXzW9tHY","colab_type":"text"},"source":["BERT model accept only a specific type of input and the datasets are usually structured to have have the following four features:\n","\n","<ul> guid : A unique id that represents an observation.</ul>\n","<ul> text_a : The text we need to classify into given categories </ul>\n","<ul> text_b: It is used when we're training a model to understand the relationship between sentences and it does not apply for classification problems. </ul>\n"," <ul>label: It consists of the labels or classes or categories that a given text belongs to. </ul>\n","\n","In our dataset we have text_a and label. The following code block will create objects for each of the above mentioned features for all the records in our dataset using the InputExample class provided in the BERT library."]},{"cell_type":"code","metadata":{"id":"H6lKWW-p6wIV","colab_type":"code","colab":{}},"source":["train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uI4ZBwG7ljw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":213},"outputId":"228023ee-f1fc-4d52-92af-bc7041e2f321","executionInfo":{"status":"ok","timestamp":1581401577915,"user_tz":420,"elapsed":493,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n","print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n","print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n","print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Row 0 - guid of training set :  None\n","\n","__________\n","Row 0 - text_a of training set :  Contrary to the above, PSEG personnel did not accomplish the 22 CAC maintenance in accordance with prescribed procedures.\n","\n","__________\n","Row 0 - text_b of training set :  None\n","\n","__________\n","Row 0 - label of training set :  1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iZkgdRtw91EV","colab_type":"text"},"source":["The following code block loads the pre-trained BERT model and initializers a tokenizer object for tokenizing the texts."]},{"cell_type":"code","metadata":{"id":"0M415PfB7qCH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":142},"outputId":"2faae98a-303a-46c0-9be9-e459f4f48338","executionInfo":{"status":"ok","timestamp":1581401583191,"user_tz":420,"elapsed":2923,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["# This is a path to an uncased (all lowercase) version of BERT\n","\n","#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gX8XN5ms7rYr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1941a7b0-18fb-4545-e23e-19bbb4576bbe","executionInfo":{"status":"ok","timestamp":1581401586256,"user_tz":420,"elapsed":899,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["# We'll set sequences to be at most 128 tokens long.\n","MAX_SEQ_LENGTH = 128\n","\n","# Convert our train and validation features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 389\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 389\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] contrary to the above , ps ##eg personnel did not accomplish the 22 ca ##c maintenance in accordance with prescribed procedures . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] contrary to the above , ps ##eg personnel did not accomplish the 22 ca ##c maintenance in accordance with prescribed procedures . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10043 2000 1996 2682 1010 8827 13910 5073 2106 2025 14570 1996 2570 6187 2278 6032 1999 10388 2007 16250 8853 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10043 2000 1996 2682 1010 8827 13910 5073 2106 2025 14570 1996 2570 6187 2278 6032 1999 10388 2007 16250 8853 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the cause of this event was attributed to the failure of the operating crew to establish clear termination criteria for stopping the cool ##down based on low steam generator levels and the lack of clear termination criteria guidance in the procedure for maintaining steam generator levels during a cool ##down . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the cause of this event was attributed to the failure of the operating crew to establish clear termination criteria for stopping the cool ##down based on low steam generator levels and the lack of clear termination criteria guidance in the procedure for maintaining steam generator levels during a cool ##down . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 3426 1997 2023 2724 2001 7108 2000 1996 4945 1997 1996 4082 3626 2000 5323 3154 18287 9181 2005 7458 1996 4658 7698 2241 2006 2659 5492 13103 3798 1998 1996 3768 1997 3154 18287 9181 8606 1999 1996 7709 2005 8498 5492 13103 3798 2076 1037 4658 7698 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 3426 1997 2023 2724 2001 7108 2000 1996 4945 1997 1996 4082 3626 2000 5323 3154 18287 9181 2005 7458 1996 4658 7698 2241 2006 2659 5492 13103 3798 1998 1996 3768 1997 3154 18287 9181 8606 1999 1996 7709 2005 8498 5492 13103 3798 2076 1037 4658 7698 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] as part of the walk ##down ##s , the inspectors focused on the existence of sufficient emergency lighting for access and e ##gre ##ss to areas and for performing necessary equipment operations . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] as part of the walk ##down ##s , the inspectors focused on the existence of sufficient emergency lighting for access and e ##gre ##ss to areas and for performing necessary equipment operations . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2004 2112 1997 1996 3328 7698 2015 1010 1996 28421 4208 2006 1996 4598 1997 7182 5057 7497 2005 3229 1998 1041 17603 4757 2000 2752 1998 2005 4488 4072 3941 3136 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2004 2112 1997 1996 3328 7698 2015 1010 1996 28421 4208 2006 1996 4598 1997 7182 5057 7497 2005 3229 1998 1041 17603 4757 2000 2752 1998 2005 4488 4072 3941 3136 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] ( section 1 ##r ##0 ##5 . 5 ( b ) ( 1 ) , failure to ensure operators required for safe shut ##down were on - site ) b . license ##e - identified violations violations of very low safety significance or severity level iv that were identified by the license ##e have been reviewed by the inspectors . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] ( section 1 ##r ##0 ##5 . 5 ( b ) ( 1 ) , failure to ensure operators required for safe shut ##down were on - site ) b . license ##e - identified violations violations of very low safety significance or severity level iv that were identified by the license ##e have been reviewed by the inspectors . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1006 2930 1015 2099 2692 2629 1012 1019 1006 1038 1007 1006 1015 1007 1010 4945 2000 5676 9224 3223 2005 3647 3844 7698 2020 2006 1011 2609 1007 1038 1012 6105 2063 1011 4453 13302 13302 1997 2200 2659 3808 7784 2030 18976 2504 4921 2008 2020 4453 2011 1996 6105 2063 2031 2042 8182 2011 1996 28421 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1006 2930 1015 2099 2692 2629 1012 1019 1006 1038 1007 1006 1015 1007 1010 4945 2000 5676 9224 3223 2005 3647 3844 7698 2020 2006 1011 2609 1007 1038 1012 6105 2063 1011 4453 13302 13302 1997 2200 2659 3808 7784 2030 18976 2504 4921 2008 2020 4453 2011 1996 6105 2063 2031 2042 8182 2011 1996 28421 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] aa [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] aa [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 9779 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 9779 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 98\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 98\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] analysis : the inspectors determined that the failure to obtain nr ##c approval prior to making a change which was adverse to safe shut ##down was contrary to license conditions 2 . e and 3 . g for units 2 and 3 , respectively , and was a performance deficiency . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] analysis : the inspectors determined that the failure to obtain nr ##c approval prior to making a change which was adverse to safe shut ##down was contrary to license conditions 2 . e and 3 . g for units 2 and 3 , respectively , and was a performance deficiency . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4106 1024 1996 28421 4340 2008 1996 4945 2000 6855 17212 2278 6226 3188 2000 2437 1037 2689 2029 2001 15316 2000 3647 3844 7698 2001 10043 2000 6105 3785 1016 1012 1041 1998 1017 1012 1043 2005 3197 1016 1998 1017 1010 4414 1010 1998 2001 1037 2836 18888 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4106 1024 1996 28421 4340 2008 1996 4945 2000 6855 17212 2278 6226 3188 2000 2437 1037 2689 2029 2001 15316 2000 3647 3844 7698 2001 10043 2000 6105 3785 1016 1012 1041 1998 1017 1012 1043 2005 3197 1016 1998 1017 1010 4414 1010 1998 2001 1037 2836 18888 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] additionally , so ##p 23 . 300 , breaker operations , section 6 . 5 . 2 , detailed procedure ( for installation of hk style ground truck ) was not complied with by failing to place \" ground truck installed \" pl ##aca ##rds on the front compartment door of bus 65 ##e following installation of a ground truck . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] additionally , so ##p 23 . 300 , breaker operations , section 6 . 5 . 2 , detailed procedure ( for installation of hk style ground truck ) was not complied with by failing to place \" ground truck installed \" pl ##aca ##rds on the front compartment door of bus 65 ##e following installation of a ground truck . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5678 1010 2061 2361 2603 1012 3998 1010 24733 3136 1010 2930 1020 1012 1019 1012 1016 1010 6851 7709 1006 2005 8272 1997 22563 2806 2598 4744 1007 2001 2025 26946 2007 2011 7989 2000 2173 1000 2598 4744 5361 1000 20228 19629 17811 2006 1996 2392 15273 2341 1997 3902 3515 2063 2206 8272 1997 1037 2598 4744 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5678 1010 2061 2361 2603 1012 3998 1010 24733 3136 1010 2930 1020 1012 1019 1012 1016 1010 6851 7709 1006 2005 8272 1997 22563 2806 2598 4744 1007 2001 2025 26946 2007 2011 7989 2000 2173 1000 2598 4744 5361 1000 20228 19629 17811 2006 1996 2392 15273 2341 1997 3902 3515 2063 2206 8272 1997 1037 2598 4744 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] in 2009 , a nos ( nuclear oversight - - quality assurance ) surveillance , p ##bn 10 - 00 ##3 , \" 2009 4th quarter site quarter priority dq ##s roll - up , \" ( p ##bn ##p - q ##a - 10 - 01 ) , was conducted of the be ##cht ##el cap and concluded the be ##cht ##el q ##a [ quality assurance ] program for the ep ##u project during the unit 2 refueling out ##age 30 was inadequate and did not prevent significant performance def ##iciencies from occurring and recurring . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] in 2009 , a nos ( nuclear oversight - - quality assurance ) surveillance , p ##bn 10 - 00 ##3 , \" 2009 4th quarter site quarter priority dq ##s roll - up , \" ( p ##bn ##p - q ##a - 10 - 01 ) , was conducted of the be ##cht ##el cap and concluded the be ##cht ##el q ##a [ quality assurance ] program for the ep ##u project during the unit 2 refueling out ##age 30 was inadequate and did not prevent significant performance def ##iciencies from occurring and recurring . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1999 2268 1010 1037 16839 1006 4517 15709 1011 1011 3737 16375 1007 9867 1010 1052 24700 2184 1011 4002 2509 1010 1000 2268 4343 4284 2609 4284 9470 25410 2015 4897 1011 2039 1010 1000 1006 1052 24700 2361 1011 1053 2050 1011 2184 1011 5890 1007 1010 2001 4146 1997 1996 2022 10143 2884 6178 1998 5531 1996 2022 10143 2884 1053 2050 1031 3737 16375 1033 2565 2005 1996 4958 2226 2622 2076 1996 3131 1016 23026 2041 4270 2382 2001 14710 1998 2106 2025 4652 3278 2836 13366 28227 2013 10066 1998 10694 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1999 2268 1010 1037 16839 1006 4517 15709 1011 1011 3737 16375 1007 9867 1010 1052 24700 2184 1011 4002 2509 1010 1000 2268 4343 4284 2609 4284 9470 25410 2015 4897 1011 2039 1010 1000 1006 1052 24700 2361 1011 1053 2050 1011 2184 1011 5890 1007 1010 2001 4146 1997 1996 2022 10143 2884 6178 1998 5531 1996 2022 10143 2884 1053 2050 1031 3737 16375 1033 2565 2005 1996 4958 2226 2622 2076 1996 3131 1016 23026 2041 4270 2382 2001 14710 1998 2106 2025 4652 3278 2836 13366 28227 2013 10066 1998 10694 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] in addition , the license ##e failed to identify the presence of transient comb ##ust ##ible ##s through fire watches conducted as required by the fire protection program . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] in addition , the license ##e failed to identify the presence of transient comb ##ust ##ible ##s through fire watches conducted as required by the fire protection program . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1999 2804 1010 1996 6105 2063 3478 2000 6709 1996 3739 1997 25354 22863 19966 7028 2015 2083 2543 12197 4146 2004 3223 2011 1996 2543 3860 2565 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1999 2804 1010 1996 6105 2063 3478 2000 6709 1996 3739 1997 25354 22863 19966 7028 2015 2083 2543 12197 4146 2004 3223 2011 1996 2543 3860 2565 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the correct ##ive actions included verify ##ing that the indications did not structurally affect the reactor building in these instances , initiating condition report c - 2014 - 00 ##59 ##7 , and scheduling the affected areas for review during the upcoming 5 - year inspection . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the correct ##ive actions included verify ##ing that the indications did not structurally affect the reactor building in these instances , initiating condition report c - 2014 - 00 ##59 ##7 , and scheduling the affected areas for review during the upcoming 5 - year inspection . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6149 3512 4506 2443 20410 2075 2008 1996 24936 2106 2025 29060 7461 1996 13308 2311 1999 2122 12107 1010 26616 4650 3189 1039 1011 2297 1011 4002 28154 2581 1010 1998 19940 1996 5360 2752 2005 3319 2076 1996 9046 1019 1011 2095 10569 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6149 3512 4506 2443 20410 2075 2008 1996 24936 2106 2025 29060 7461 1996 13308 2311 1999 2122 12107 1010 26616 4650 3189 1039 1011 2297 1011 4002 28154 2581 1010 1998 19940 1996 5360 2752 2005 3319 2076 1996 9046 1019 1011 2095 10569 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"c6OvJhBw7xv6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"e115251e-faf6-4869-ad43-55eb7e9d4f8e","executionInfo":{"status":"ok","timestamp":1581401589809,"user_tz":420,"elapsed":438,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["#Example on first observation in the training set\n","print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n","print(\"-\"*30)\n","print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n","print(\"-\"*30)\n","print(\"Input IDs : \", train_features[0].input_ids)\n","print(\"-\"*30)\n","print(\"Input Masks : \", train_features[0].input_mask)\n","print(\"-\"*30)\n","print(\"Segment IDs : \", train_features[0].segment_ids)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Sentence :  Contrary to the above, PSEG personnel did not accomplish the 22 CAC maintenance in accordance with prescribed procedures.\n","------------------------------\n","Tokens :  ['contrary', 'to', 'the', 'above', ',', 'ps', '##eg', 'personnel', 'did', 'not', 'accomplish', 'the', '22', 'ca', '##c', 'maintenance', 'in', 'accordance', 'with', 'prescribed', 'procedures', '.']\n","------------------------------\n","Input IDs :  [101, 10043, 2000, 1996, 2682, 1010, 8827, 13910, 5073, 2106, 2025, 14570, 1996, 2570, 6187, 2278, 6032, 1999, 10388, 2007, 16250, 8853, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","------------------------------\n","Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","------------------------------\n","Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vbhuq6SF98L3","colab_type":"text"},"source":["## 3. Creating a Multi-Class Classifier Model"]},{"cell_type":"code","metadata":{"id":"kjlBbs5579Xq","colab_type":"code","colab":{}},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHngc2ss-SXL","colab_type":"code","colab":{}},"source":["#A function that adapts our model to work for training, evaluation, and prediction.\n","\n","# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        \n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","            }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gI7xeLmI-EnS","colab_type":"code","colab":{}},"source":["# Compute train and warmup steps from batch size\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 10.0\n","# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 300\n","SAVE_SUMMARY_STEPS = 100\n","\n","# Compute train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nl58inNm-XI_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"5eaca1d7-c866-4ad8-eea8-85811ad4cad0","executionInfo":{"status":"ok","timestamp":1581401607331,"user_tz":420,"elapsed":420,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["#Initializing the model and the estimator\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})"],"execution_count":25,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/DS_Lab/Models1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd6148362e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/DS_Lab/Models1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd6148362e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0GCKS2MZ-aYs","colab_type":"code","colab":{}},"source":["# Create an input function for training. drop_remainder = True for using TPUs.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)\n","\n","# Create an input function for validating. drop_remainder = True for using TPUs.\n","val_input_fn = run_classifier.input_fn_builder(\n","    features=val_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zkzR8Xm-fuj","colab_type":"text"},"source":["## 4. Training & Evaluating"]},{"cell_type":"code","metadata":{"id":"x_M_5gbL-h8D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4f4da80a-538f-498b-ba02-b9704b1f1c72","executionInfo":{"status":"ok","timestamp":1581401785150,"user_tz":420,"elapsed":172207,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-22-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-22-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.9396447, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.9396447, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.01306\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.01306\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.003637433, step = 100 (98.713 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.003637433, step = 100 (98.713 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 121 into /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 121 into /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.002772362.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.002772362.\n"],"name":"stderr"},{"output_type":"stream","text":["Training took time  0:02:51.716120\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w0Ry6dVt-oRI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"ae202084-ac12-4e36-819f-c2fc83d1d7dc","executionInfo":{"status":"ok","timestamp":1581401814929,"user_tz":420,"elapsed":20956,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["#Evaluating the model with Validation set\n","val_acc = estimator.evaluate(input_fn=val_input_fn, steps=None)['eval_accuracy']"],"execution_count":28,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-02-11T06:16:45Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-02-11T06:16:45Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt-121\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt-121\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-02-11-06:16:53\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-02-11-06:16:53\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 121: eval_accuracy = 0.877551, false_negatives = 2.0, false_positives = 10.0, global_step = 121, loss = 0.26970968, true_negatives = 41.0, true_positives = 45.0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 121: eval_accuracy = 0.877551, false_negatives = 2.0, false_positives = 10.0, global_step = 121, loss = 0.26970968, true_negatives = 41.0, true_positives = 45.0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 121: /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt-121\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 121: /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt-121\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"xWT7Okjw-saD","colab_type":"text"},"source":["## 5. Predicting For Test Set"]},{"cell_type":"code","metadata":{"id":"fV9Ju6QI-ukX","colab_type":"code","colab":{}},"source":["\"\"\"{'U':0, 'N': 1} \"\"\"\n","\n","# A method to get predictions\n","def getPrediction(df_test):\n","\n","  in_sentences = list(df_test['text'])\n","  #A list to map the actual labels to the predictions\n","  labels = ['U', 'N']\n","\n","  #Transforming the test data into BERT accepted form\n","  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n","  \n","  #Creating input features for Test data\n","  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","  #Predicting the classes \n","  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n","  predictions = estimator.predict(predict_input_fn)\n","  pred = [labels[prediction['labels']] for prediction in predictions]\n","  df_test['Y'] = [labels[Y] for Y in list(df_test['Y'])]\n","  df_test['Predicted_Values'] = pred\n","\n","  total_matching = sum(df_test['Y'] == pred)\n","  total = len(pred)\n","  acc = total_matching/total\n","  print('accuracy = ',acc)\n","  return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYBZ4tWM-7x4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ce1383ec-74a1-47ef-d7ff-2fac9a65163d","executionInfo":{"status":"ok","timestamp":1581401858571,"user_tz":420,"elapsed":6781,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["test_evals = getPrediction(df_test)\n","test_acc = test_evals"],"execution_count":30,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 147\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 147\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] however , because of their very low safety significance , and because the issues were entered into your correct ##ive action program , the nr ##c is treating the issues as non - cited violations ( nc ##vs ) in accordance with section 2 . 3 . 2 of the nr ##c enforcement policy . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] however , because of their very low safety significance , and because the issues were entered into your correct ##ive action program , the nr ##c is treating the issues as non - cited violations ( nc ##vs ) in accordance with section 2 . 3 . 2 of the nr ##c enforcement policy . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2174 1010 2138 1997 2037 2200 2659 3808 7784 1010 1998 2138 1996 3314 2020 3133 2046 2115 6149 3512 2895 2565 1010 1996 17212 2278 2003 12318 1996 3314 2004 2512 1011 6563 13302 1006 13316 15088 1007 1999 10388 2007 2930 1016 1012 1017 1012 1016 1997 1996 17212 2278 7285 3343 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2174 1010 2138 1997 2037 2200 2659 3808 7784 1010 1998 2138 1996 3314 2020 3133 2046 2115 6149 3512 2895 2565 1010 1996 17212 2278 2003 12318 1996 3314 2004 2512 1011 6563 13302 1006 13316 15088 1007 1999 10388 2007 2930 1016 1012 1017 1012 1016 1997 1996 17212 2278 7285 3343 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] additionally , a license ##e identified violation is listed in section 4 ##oa ##7 of this report . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] additionally , a license ##e identified violation is listed in section 4 ##oa ##7 of this report . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5678 1010 1037 6105 2063 4453 11371 2003 3205 1999 2930 1018 10441 2581 1997 2023 3189 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5678 1010 1037 6105 2063 4453 11371 2003 3205 1999 2930 1018 10441 2581 1997 2023 3189 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] if you contest the subject or severity of any nc ##vs , you should provide a response within 30 days of the date of this inspection report , with the basis for your denial , to the u . s . nuclear regulatory commission , at ##t ##n : document control desk , washington dc 205 ##55 - 000 ##1 ; with a copy to the regional administrator , u . s . nuclear regulatory commission a _ region iii , 244 ##3 warren ##ville road , suite 210 , li ##sle , il 60 ##53 ##2 - 435 ##2 ; the director , office of enforcement , u . s . nuclear regulatory commission , washington , dc 205 ##55 - 000 ##1 ; and [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] if you contest the subject or severity of any nc ##vs , you should provide a response within 30 days of the date of this inspection report , with the basis for your denial , to the u . s . nuclear regulatory commission , at ##t ##n : document control desk , washington dc 205 ##55 - 000 ##1 ; with a copy to the regional administrator , u . s . nuclear regulatory commission a _ region iii , 244 ##3 warren ##ville road , suite 210 , li ##sle , il 60 ##53 ##2 - 435 ##2 ; the director , office of enforcement , u . s . nuclear regulatory commission , washington , dc 205 ##55 - 000 ##1 ; and [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2065 2017 5049 1996 3395 2030 18976 1997 2151 13316 15088 1010 2017 2323 3073 1037 3433 2306 2382 2420 1997 1996 3058 1997 2023 10569 3189 1010 2007 1996 3978 2005 2115 14920 1010 2000 1996 1057 1012 1055 1012 4517 10738 3222 1010 2012 2102 2078 1024 6254 2491 4624 1010 2899 5887 16327 24087 1011 2199 2487 1025 2007 1037 6100 2000 1996 3164 8911 1010 1057 1012 1055 1012 4517 10738 3222 1037 1035 2555 3523 1010 24194 2509 6031 3077 2346 1010 7621 12875 1010 5622 25016 1010 6335 3438 22275 2475 1011 24125 2475 1025 1996 2472 1010 2436 1997 7285 1010 1057 1012 1055 1012 4517 10738 3222 1010 2899 1010 5887 16327 24087 1011 2199 2487 1025 1998 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2065 2017 5049 1996 3395 2030 18976 1997 2151 13316 15088 1010 2017 2323 3073 1037 3433 2306 2382 2420 1997 1996 3058 1997 2023 10569 3189 1010 2007 1996 3978 2005 2115 14920 1010 2000 1996 1057 1012 1055 1012 4517 10738 3222 1010 2012 2102 2078 1024 6254 2491 4624 1010 2899 5887 16327 24087 1011 2199 2487 1025 2007 1037 6100 2000 1996 3164 8911 1010 1057 1012 1055 1012 4517 10738 3222 1037 1035 2555 3523 1010 24194 2509 6031 3077 2346 1010 7621 12875 1010 5622 25016 1010 6335 3438 22275 2475 1011 24125 2475 1025 1996 2472 1010 2436 1997 7285 1010 1057 1012 1055 1012 4517 10738 3222 1010 2899 1010 5887 16327 24087 1011 2199 2487 1025 1998 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] m . pac ##ili ##o [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] m . pac ##ili ##o [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1049 1012 14397 18622 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1049 1012 14397 18622 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] - 2 - [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] - 2 - [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1011 1016 1011 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1011 1016 1011 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt-121\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models1/model.ckpt-121\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["accuracy =  0.9115646258503401\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Cp9Ugu0P-8uH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"c2ff45e4-09b4-43ca-c1aa-d92ec8634b6b","executionInfo":{"status":"ok","timestamp":1581401868694,"user_tz":420,"elapsed":2036,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["df_test.to_csv('Binary_Classification.csv', index = False)\n","!mv Binary_Classification.csv \"/GD/My Drive/Colab Notebooks/DS_Lab/Results/\"\n","df_test.head()"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label_SALLY</th>\n","      <th>text</th>\n","      <th>line</th>\n","      <th>start_pos</th>\n","      <th>end_pos</th>\n","      <th>file</th>\n","      <th>Y</th>\n","      <th>Predicted_Values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>U</td>\n","      <td>However, because of their very low safety sign...</td>\n","      <td>5</td>\n","      <td>793</td>\n","      <td>1047</td>\n","      <td>ML11300A116.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>U</td>\n","      <td>Additionally, a licensee identified violation ...</td>\n","      <td>5</td>\n","      <td>1047</td>\n","      <td>1134</td>\n","      <td>ML11300A116.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>U</td>\n","      <td>If you contest the subject or severity of any ...</td>\n","      <td>5</td>\n","      <td>1134</td>\n","      <td>1720</td>\n","      <td>ML11300A116.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>U</td>\n","      <td>M. Pacilio</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>ML11300A116.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>U</td>\n","      <td>-2-</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>ML11300A116.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label_SALLY  ... Predicted_Values\n","9            U  ...                U\n","10           U  ...                U\n","11           U  ...                U\n","13           U  ...                U\n","14           U  ...                U\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"_pnfVwax_CZq","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix\n","\n","pred_labels = list(set(df_test['Predicted_Values']))\n","\n","conf_mat = confusion_matrix(df_test['Y'], df_test['Predicted_Values'], pred_labels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CN76LT-qw33Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":77},"outputId":"f1529565-71b2-4fa4-cb38-4a5e76dcf5d0","executionInfo":{"status":"ok","timestamp":1581401875006,"user_tz":420,"elapsed":529,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["final_result = pd.DataFrame(columns = ['Coder','Train_Accuracy','Val_Accuracy','Test_Accuracy','#TestData','#AllData'])\n","list = []\n","list.append('Binary_Classification')\n","final_result['Coder'] = list\n","list = []\n","list.append(val_acc)\n","final_result['Val_Accuracy'] = list\n","list = []\n","list.append(test_acc)\n","final_result['Test_Accuracy'] = list\n","list = []\n","list.append(len(df_test['text']))\n","final_result['#TestData'] = list\n","list = []\n","list.append(len(df['text']))\n","final_result['#AllData'] = list\n","list = []\n","list.append(pred_labels)\n","final_result['Classes'] = list\n","list = []\n","list.append(conf_mat)\n","final_result['Confusion Matrix'] = list\n","final_result"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Coder</th>\n","      <th>Train_Accuracy</th>\n","      <th>Val_Accuracy</th>\n","      <th>Test_Accuracy</th>\n","      <th>#TestData</th>\n","      <th>#AllData</th>\n","      <th>Classes</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Binary_Classification</td>\n","      <td>NaN</td>\n","      <td>0.877551</td>\n","      <td>0.911565</td>\n","      <td>147</td>\n","      <td>634</td>\n","      <td>[N, U]</td>\n","      <td>[[70, 6], [7, 64]]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   Coder Train_Accuracy  ...  Classes    Confusion Matrix\n","0  Binary_Classification            NaN  ...   [N, U]  [[70, 6], [7, 64]]\n","\n","[1 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"CU_J7IEQw7NR","colab_type":"code","colab":{}},"source":["if not tf.io.gfile.exists(\"/GD/My Drive/Colab Notebooks/DS_Lab/Results/Final_Results.csv\"):\n","  final_result.to_csv(\"Final_Results.csv\", header=True)\n","else:\n","  final_result.to_csv(\"Final_Results.csv\", mode='a', header=False)\n","!mv Final_Results.csv \"/GD/My Drive/Colab Notebooks/DS_Lab/Results/\""],"execution_count":0,"outputs":[]}]}