{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_multiclass.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNVW/wtTXTTv6SZjbjAg+Mw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JOGbuqllYZzc","colab_type":"text"},"source":["# Multi-Class Classification using BERT"]},{"cell_type":"markdown","metadata":{"id":"a7SK23zTYors","colab_type":"text"},"source":["Classifying the sentences from IRs (Instruction Reports) into different labels of \"Human Errors\" i.e.: <Br>\n","T: Team Cognition <br>\n","P: Procedural <br>\n","O: Organizational <br>\n","D: Design <br>\n","H: Human <br>\n","<br>\n","For Training Data, we have sentences labelled by the coders - Sally, Frenard and Trixy<BR>\n","<br>\n","The coders have also labelled sentences as 'U': useless\n"]},{"cell_type":"code","metadata":{"id":"RJkKeu8CFyMQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4c1d498d-3b13-45a0-8a7a-564f0e240dfd","executionInfo":{"status":"ok","timestamp":1588032130415,"user_tz":420,"elapsed":624,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}}},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0TfOfxR6XE66","colab_type":"text"},"source":["## 1. Configuring GPU and Libraries"]},{"cell_type":"code","metadata":{"id":"Plq0MmjTZk4w","colab_type":"code","outputId":"35b7878a-3cb2-47bf-958b-70e2675ea0de","executionInfo":{"status":"ok","timestamp":1584407076503,"user_tz":420,"elapsed":3714,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["# verify GPU availability\n","import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yMuWIE5AbITl","colab_type":"code","outputId":"d22a3ed1-460f-4e50-84a5-3a7b55de1503","executionInfo":{"status":"ok","timestamp":1584407089002,"user_tz":420,"elapsed":11090,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":106}},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.5 GB  | Proc size: 495.5 MB\n","GPU RAM Free: 14968MB | Used: 111MB | Util   1% | Total 15079MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eiQeI3A2bL2r","colab_type":"code","outputId":"c37c3758-ef52-41ec-860f-1fdfef0dc10c","executionInfo":{"status":"ok","timestamp":1584407128571,"user_tz":420,"elapsed":2694,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["!ps ax | grep python"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     26 ?        Sl     0:05 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --MappingKernelManager.root_dir=\"/content\"\n","   1884 ?        Ssl    0:03 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-16529757-da95-4633-b4a7-c8f16d149fe5.json\n","   1978 ?        S      0:00 /bin/bash -c ps ax | grep python\n","   1980 ?        D      0:00 grep python\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Plx9wp6ubQrg","colab_type":"code","outputId":"2ff24760-cce4-4811-b798-3985e5cb1911","executionInfo":{"status":"ok","timestamp":1584407125904,"user_tz":420,"elapsed":3405,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["!pip install pytorch-pretrained-bert pytorch-nlp"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n","Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.18)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.18)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.18->boto3->pytorch-pretrained-bert) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7KFvDTVPbTO_","colab_type":"code","outputId":"a7ea5b35-3afa-40f3-caf2-a91ebb8fa171","executionInfo":{"status":"ok","timestamp":1584407132897,"user_tz":420,"elapsed":2161,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# BERT imports\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import string\n","import os\n","import glob\n","% matplotlib inline\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"KwZNnTGzbaPP","colab_type":"code","colab":{}},"source":["torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOUu4H9BRF_v","colab_type":"code","outputId":"9dcf7b42-fab0-4c54-a28d-6fd39fe3bb0a","executionInfo":{"status":"ok","timestamp":1584407137692,"user_tz":420,"elapsed":923,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount(\"/GD\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /GD; to attempt to forcibly remount, call drive.mount(\"/GD\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L1SikjVqR2IP","colab_type":"code","outputId":"0085f007-eed2-4757-f465-d9869bafb789","executionInfo":{"status":"ok","timestamp":1584407141477,"user_tz":420,"elapsed":856,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","print(\"tensorflow version : \", tf.__version__)\n","print(\"tensorflow_hub version : \", hub.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensorflow version :  1.15.0\n","tensorflow_hub version :  0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cJSi_DvLR6zs","colab_type":"code","outputId":"f336ae82-4c52-4a4f-a815-0d666d47c513","executionInfo":{"status":"ok","timestamp":1584407146965,"user_tz":420,"elapsed":3295,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["\n","#Installing BERT module\n","!pip install bert-tensorflow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MzLMqblbR_9n","colab_type":"code","outputId":"50fed8f7-7174-4f54-e268-22377e6f1c1c","executionInfo":{"status":"ok","timestamp":1584407150727,"user_tz":420,"elapsed":893,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["\n","#Importing BERT modules\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cRkuFVGySFVG","colab_type":"code","outputId":"a4e6ac9b-9253-4bad-b33d-17374da2d803","executionInfo":{"status":"ok","timestamp":1584407155215,"user_tz":420,"elapsed":1090,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["OUTPUT_DIR = '/GD/My Drive/Colab Notebooks/DS_Lab/Models/'\n","\n","#@markdown Whether or not to clear/delete the directory and create a new one\n","DO_DELETE = True #@param {type:\"boolean\"}\n","\n","if DO_DELETE:\n","  try:\n","    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n","  except:\n","    pass\n","\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["***** Model output directory: /GD/My Drive/Colab Notebooks/DS_Lab/Models/ *****\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q-FGPDrAXz4I","colab_type":"text"},"source":["## 2. Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"8hAgaBu2fB9M","colab_type":"code","colab":{}},"source":["df = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Agtwor-5SWF5","colab_type":"code","outputId":"928569a9-55a5-4c5b-9aaa-f6bf288d72d7","executionInfo":{"status":"ok","timestamp":1584407161560,"user_tz":420,"elapsed":1101,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":336}},"source":["files = [f for f in glob.glob(\"*.csv\")]\n","df_raw = pd.DataFrame()\n","\n","for file in files:\n"," \n","  df = pd.read_csv(file)\n","  df['text'] = df['text'].apply(str)\n","  df_raw = pd.concat([df_raw , df], ignore_index=True)\n","\n","df = df_raw.dropna()\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n","of pandas will change to not sort by default.\n","\n","To accept the future behavior, pass 'sort=False'.\n","\n","To retain the current behavior and silence the warning, pass 'sort=True'.\n","\n","  \n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>end_pos</th>\n","      <th>file</th>\n","      <th>label_Frenard</th>\n","      <th>label_SALLY</th>\n","      <th>line</th>\n","      <th>start_pos</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>43</td>\n","      <td>ML13182A476.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>UNITED STATES NUCLEAR REGULATORY COMMISSION</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>87</td>\n","      <td>ML13182A476.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>REGION I 2100 RENAISSANCE BOULEVARD, SUITE 100...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12</td>\n","      <td>ML13182A476.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1-Jul-13</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>146</td>\n","      <td>ML13182A476.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>Mr. Michael J. Pacilio Senior Vice President, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>292</td>\n","      <td>ML13182A476.txt</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>5</td>\n","      <td>146</td>\n","      <td>Warrenville, IL 60555 SUBJECT: LIMERICK GENERA...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   end_pos  ...                                               text\n","0       43  ...        UNITED STATES NUCLEAR REGULATORY COMMISSION\n","1       87  ...  REGION I 2100 RENAISSANCE BOULEVARD, SUITE 100...\n","2       12  ...                                           1-Jul-13\n","3      146  ...  Mr. Michael J. Pacilio Senior Vice President, ...\n","4      292  ...  Warrenville, IL 60555 SUBJECT: LIMERICK GENERA...\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"4ioPtEoI7M1l","colab_type":"code","colab":{}},"source":["# Get labels of these coders\n","TRAINING_LABEL = ['label_SALLY', 'label_Frenard']\n","\n","# Get labels of sentences, which were labelled same by the coders (excluding 'U')\n","def get_similar(row):\n","    if len(TRAINING_LABEL)==2:\n","        if row[TRAINING_LABEL[0]] == row[TRAINING_LABEL[1]] and row[TRAINING_LABEL[0]] != 'U':\n","            return row[TRAINING_LABEL[0]]\n","        else:\n","            return np.NaN\n","    if len(TRAINING_LABEL)==3:\n","        if row[TRAINING_LABEL[0]] == row[TRAINING_LABEL[1]] == row[TRAINING_LABEL[2]] and row[TRAINING_LABEL[0]] != 'U':\n","            return row[TRAINING_LABEL[0]]\n","        else:\n","            return np.NaN\n","\n","# Get labels of sentences, which were labelled different by the coders (excluding 'U')\n","def get_different(row):\n","    if len(TRAINING_LABEL) == 2:\n","        if row[TRAINING_LABEL[0]] == 'U' or row[TRAINING_LABEL[0]] == row[TRAINING_LABEL[1]]:\n","            return np.NaN\n","        else:\n","            return row[TRAINING_LABEL[0]]\n","    if len(TRAINING_LABEL) == 3:\n","        if row[TRAINING_LABEL[0]] == 'U' or row[TRAINING_LABEL[0]] == row[TRAINING_LABEL[1]] == row[TRAINING_LABEL[2]]:\n","            return np.NaN\n","        else:\n","            return row[TRAINING_LABEL[0]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"puTnh778TJFj","colab_type":"code","outputId":"ab840a46-7aa8-453e-92c1-670ba3e7ea81","executionInfo":{"status":"ok","timestamp":1584407168523,"user_tz":420,"elapsed":1010,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":248}},"source":["# Get label of a sentence (first label if there are multiple labels)\n","# Get NULL if the label is 'U'\n","def class_label_handler(class_label):\n","  if 'U' in class_label:\n","    return np.NaN\n","  else:\n","    return class_label.split(',')[0]\n","\n","for label in TRAINING_LABEL:  \n","  df[label] = df[label].apply(class_label_handler)\n","\n","if len(TRAINING_LABEL) > 1:\n","  df['Y'] = df.apply(get_similar, axis=1)\n","\n","# Drop rows with NULL labels\n","for label in TRAINING_LABEL:\n","  df = df.drop(label, axis=1)\n","  \n","df = df.dropna()\n","\n","label_idx = {'T':0, 'P': 1, 'O': 2, 'D': 3, 'H': 4}\n","def changing_labels_to_integers(class_label):\n","  return label_idx[class_label]\n","\n","df['Y']=df['Y'].apply(changing_labels_to_integers)\n","len(df['Y'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["70"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"dCfV1s1xU8ST","colab_type":"code","colab":{}},"source":["# Splitting Training and Test\n","TRAIN_TEST_SPLIT = 0.8\n","msk = np.random.rand(len(df)) < TRAIN_TEST_SPLIT\n","df_train = df[msk]\n","df_test = df[~msk]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-oigFv1VBmE","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","train, val =  train_test_split(df_train, test_size = 0.2, random_state = 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnK62k0nVMMk","colab_type":"code","outputId":"fd1565f4-620a-4cc3-976d-83af4b4c016c","executionInfo":{"status":"ok","timestamp":1584407177261,"user_tz":420,"elapsed":891,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["print(\"Training Set Shape :\", train.shape)\n","print(\"Validation Set Shape :\", val.shape)\n","print(\"Test Set Shape :\", df_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Set Shape : (46, 6)\n","Validation Set Shape : (12, 6)\n","Test Set Shape : (12, 6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hMCe0wKrVPbG","colab_type":"code","colab":{}},"source":["DATA_COLUMN = 'text'\n","LABEL_COLUMN = 'Y'\n","# The list containing all the classes (train['SECTION'].unique())\n","label_list = [0, 1, 2, 3, 4]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z2Bb41OKx-4l","colab_type":"text"},"source":["BERT model accept only a specific type of input and the datasets are usually structured to have have the following four features:\n","\n","<ul> guid : A unique id that represents an observation.</ul>\n","<ul> text_a : The text we need to classify into given categories </ul>\n","<ul> text_b: It is used when we're training a model to understand the relationship between sentences and it does not apply for classification problems. </ul>\n"," <ul>label: It consists of the labels or classes or categories that a given text belongs to. </ul>\n","\n","In our dataset we have text_a and label. The following code block will create objects for each of the above mentioned features for all the records in our dataset using the InputExample class provided in the BERT library."]},{"cell_type":"code","metadata":{"id":"NCno6biiVzqS","colab_type":"code","colab":{}},"source":["train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4koaGUEV60L","colab_type":"code","outputId":"b91a43e4-dd9a-4016-808c-d915229c2752","executionInfo":{"status":"ok","timestamp":1584407186485,"user_tz":420,"elapsed":871,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":852}},"source":["train_InputExamples"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3976    <bert.run_classifier.InputExample object at 0x...\n","686     <bert.run_classifier.InputExample object at 0x...\n","212     <bert.run_classifier.InputExample object at 0x...\n","3868    <bert.run_classifier.InputExample object at 0x...\n","1196    <bert.run_classifier.InputExample object at 0x...\n","3873    <bert.run_classifier.InputExample object at 0x...\n","2372    <bert.run_classifier.InputExample object at 0x...\n","2353    <bert.run_classifier.InputExample object at 0x...\n","1731    <bert.run_classifier.InputExample object at 0x...\n","2852    <bert.run_classifier.InputExample object at 0x...\n","2283    <bert.run_classifier.InputExample object at 0x...\n","2401    <bert.run_classifier.InputExample object at 0x...\n","1089    <bert.run_classifier.InputExample object at 0x...\n","228     <bert.run_classifier.InputExample object at 0x...\n","3878    <bert.run_classifier.InputExample object at 0x...\n","1775    <bert.run_classifier.InputExample object at 0x...\n","2738    <bert.run_classifier.InputExample object at 0x...\n","1197    <bert.run_classifier.InputExample object at 0x...\n","1202    <bert.run_classifier.InputExample object at 0x...\n","840     <bert.run_classifier.InputExample object at 0x...\n","124     <bert.run_classifier.InputExample object at 0x...\n","2206    <bert.run_classifier.InputExample object at 0x...\n","155     <bert.run_classifier.InputExample object at 0x...\n","1737    <bert.run_classifier.InputExample object at 0x...\n","2863    <bert.run_classifier.InputExample object at 0x...\n","1205    <bert.run_classifier.InputExample object at 0x...\n","1952    <bert.run_classifier.InputExample object at 0x...\n","235     <bert.run_classifier.InputExample object at 0x...\n","965     <bert.run_classifier.InputExample object at 0x...\n","2320    <bert.run_classifier.InputExample object at 0x...\n","3702    <bert.run_classifier.InputExample object at 0x...\n","3960    <bert.run_classifier.InputExample object at 0x...\n","2857    <bert.run_classifier.InputExample object at 0x...\n","952     <bert.run_classifier.InputExample object at 0x...\n","3700    <bert.run_classifier.InputExample object at 0x...\n","125     <bert.run_classifier.InputExample object at 0x...\n","2317    <bert.run_classifier.InputExample object at 0x...\n","2001    <bert.run_classifier.InputExample object at 0x...\n","685     <bert.run_classifier.InputExample object at 0x...\n","2868    <bert.run_classifier.InputExample object at 0x...\n","955     <bert.run_classifier.InputExample object at 0x...\n","1639    <bert.run_classifier.InputExample object at 0x...\n","2338    <bert.run_classifier.InputExample object at 0x...\n","151     <bert.run_classifier.InputExample object at 0x...\n","1642    <bert.run_classifier.InputExample object at 0x...\n","233     <bert.run_classifier.InputExample object at 0x...\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"fFmVNNvKV_qP","colab_type":"code","outputId":"b828fe1a-73c2-408b-a698-4b120328f867","executionInfo":{"status":"ok","timestamp":1584407191094,"user_tz":420,"elapsed":858,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n","print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n","print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n","print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Row 0 - guid of training set :  None\n","\n","__________\n","Row 0 - text_a of training set :  Contrary to the above, on October, 27, 2011, the NRC identified that the licensee failed to ensure that, during post-fire safe shutdown, Unit 1 and Unit 2 reactor coolant process variables would be maintained within those predicted for a loss of normal ac power.\n","\n","__________\n","Row 0 - text_b of training set :  None\n","\n","__________\n","Row 0 - label of training set :  2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TEgypUrBGjOB","colab_type":"text"},"source":["### Get Pre-Trained BERT Model"]},{"cell_type":"markdown","metadata":{"id":"Ng9CRAg6ytnP","colab_type":"text"},"source":["The following code block loads the pre-trained BERT model and initializers a tokenizer object for tokenizing the texts."]},{"cell_type":"code","metadata":{"id":"mTCSJ2RZWFnK","colab_type":"code","outputId":"6ed63641-36d0-4573-a7dd-1f4a1e449ca3","executionInfo":{"status":"ok","timestamp":1584407197178,"user_tz":420,"elapsed":3105,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["# This is a path to an uncased (all lowercase) version of BERT\n","\n","#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HbnkANJDZALA","colab_type":"code","outputId":"5fe3d7df-eedd-412e-830d-e400c062aa9e","executionInfo":{"status":"ok","timestamp":1584407201000,"user_tz":420,"elapsed":1156,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# We'll set sequences to be at most 128 tokens long.\n","MAX_SEQ_LENGTH = 128\n","\n","# Convert our train and validation features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 46\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 46\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] contrary to the above , on october , 27 , 2011 , the nr ##c identified that the license ##e failed to ensure that , during post - fire safe shut ##down , unit 1 and unit 2 reactor cool ##ant process variables would be maintained within those predicted for a loss of normal ac power . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] contrary to the above , on october , 27 , 2011 , the nr ##c identified that the license ##e failed to ensure that , during post - fire safe shut ##down , unit 1 and unit 2 reactor cool ##ant process variables would be maintained within those predicted for a loss of normal ac power . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10043 2000 1996 2682 1010 2006 2255 1010 2676 1010 2249 1010 1996 17212 2278 4453 2008 1996 6105 2063 3478 2000 5676 2008 1010 2076 2695 1011 2543 3647 3844 7698 1010 3131 1015 1998 3131 1016 13308 4658 4630 2832 10857 2052 2022 5224 2306 2216 10173 2005 1037 3279 1997 3671 9353 2373 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10043 2000 1996 2682 1010 2006 2255 1010 2676 1010 2249 1010 1996 17212 2278 4453 2008 1996 6105 2063 3478 2000 5676 2008 1010 2076 2695 1011 2543 3647 3844 7698 1010 3131 1015 1998 3131 1016 13308 4658 4630 2832 10857 2052 2022 5224 2306 2216 10173 2005 1037 3279 1997 3671 9353 2373 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the chosen sample point , allowed by procedure , was located on a dead leg and did not adequately compensate for the in ##oper ##able radiation monitor . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the chosen sample point , allowed by procedure , was located on a dead leg and did not adequately compensate for the in ##oper ##able radiation monitor . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 4217 7099 2391 1010 3039 2011 7709 1010 2001 2284 2006 1037 2757 4190 1998 2106 2025 23613 19079 2005 1996 1999 25918 3085 8249 8080 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 4217 7099 2391 1010 3039 2011 7709 1010 2001 2284 2006 1037 2757 4190 1998 2106 2025 23613 19079 2005 1996 1999 25918 3085 8249 8080 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] as a result , ex ##elo ##n failed to ensure that the local control circuits for several 4 ##k ##v breakers would be isolated from the effects of fire damage . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] as a result , ex ##elo ##n failed to ensure that the local control circuits for several 4 ##k ##v breakers would be isolated from the effects of fire damage . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2004 1037 2765 1010 4654 18349 2078 3478 2000 5676 2008 1996 2334 2491 13782 2005 2195 1018 2243 2615 24742 2052 2022 7275 2013 1996 3896 1997 2543 4053 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2004 1037 2765 1010 4654 18349 2078 3478 2000 5676 2008 1996 2334 2491 13782 2005 2195 1018 2243 2615 24742 2052 2022 7275 2013 1996 3896 1997 2543 4053 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the operator became distracted due to conditions in the control room and failed to perform step 5 . 3 . 1 . a prior to continuing on in the procedure . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the operator became distracted due to conditions in the control room and failed to perform step 5 . 3 . 1 . a prior to continuing on in the procedure . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6872 2150 11116 2349 2000 3785 1999 1996 2491 2282 1998 3478 2000 4685 3357 1019 1012 1017 1012 1015 1012 1037 3188 2000 5719 2006 1999 1996 7709 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6872 2150 11116 2349 2000 3785 1999 1996 2491 2282 1998 3478 2000 4685 3357 1019 1012 1017 1012 1015 1012 1037 3188 2000 5719 2006 1999 1996 7709 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 4 (id = 4)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 4 (id = 4)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the inspectors identified a finding of very low safety significance for the failure to ensure that the design basis for the dry cooling tower diesel - driven sum ##p pumps was properly implemented . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the inspectors identified a finding of very low safety significance for the failure to ensure that the design basis for the dry cooling tower diesel - driven sum ##p pumps was properly implemented . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 28421 4453 1037 4531 1997 2200 2659 3808 7784 2005 1996 4945 2000 5676 2008 1996 2640 3978 2005 1996 4318 11520 3578 7937 1011 5533 7680 2361 15856 2001 7919 7528 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 28421 4453 1037 4531 1997 2200 2659 3808 7784 2005 1996 4945 2000 5676 2008 1996 2640 3978 2005 1996 4318 11520 3578 7937 1011 5533 7680 2361 15856 2001 7919 7528 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 3 (id = 3)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 3 (id = 3)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 12\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 12\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] using the inspection manual chapter 06 ##12 , appendix b , \" issue screening , \" the inspector determined that the finding was more than minor because the performance deficiency was associated with the mit ##iga ##ting systems cornerstone attribute of human performance , and affected the cornerstone objective of ensuring the availability , reliability , and capability of systems that respond to initiating events to prevent und ##es ##ira ##ble consequences . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] using the inspection manual chapter 06 ##12 , appendix b , \" issue screening , \" the inspector determined that the finding was more than minor because the performance deficiency was associated with the mit ##iga ##ting systems cornerstone attribute of human performance , and affected the cornerstone objective of ensuring the availability , reliability , and capability of systems that respond to initiating events to prevent und ##es ##ira ##ble consequences . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2478 1996 10569 6410 3127 5757 12521 1010 22524 1038 1010 1000 3277 11326 1010 1000 1996 7742 4340 2008 1996 4531 2001 2062 2084 3576 2138 1996 2836 18888 2001 3378 2007 1996 10210 13340 3436 3001 23354 17961 1997 2529 2836 1010 1998 5360 1996 23354 7863 1997 12725 1996 11343 1010 15258 1010 1998 10673 1997 3001 2008 6869 2000 26616 2824 2000 4652 6151 2229 7895 3468 8465 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2478 1996 10569 6410 3127 5757 12521 1010 22524 1038 1010 1000 3277 11326 1010 1000 1996 7742 4340 2008 1996 4531 2001 2062 2084 3576 2138 1996 2836 18888 2001 3378 2007 1996 10210 13340 3436 3001 23354 17961 1997 2529 2836 1010 1998 5360 1996 23354 7863 1997 12725 1996 11343 1010 15258 1010 1998 10673 1997 3001 2008 6869 2000 26616 2824 2000 4652 6151 2229 7895 3468 8465 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] based on review of the actions implemented related to the reactor vessel internal ##s program aging management program , the team could not conclude that the license ##e implemented actions that would effectively manage the effects of aging during the period of extended operation . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] based on review of the actions implemented related to the reactor vessel internal ##s program aging management program , the team could not conclude that the license ##e implemented actions that would effectively manage the effects of aging during the period of extended operation . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2241 2006 3319 1997 1996 4506 7528 3141 2000 1996 13308 6258 4722 2015 2565 12520 2968 2565 1010 1996 2136 2071 2025 16519 2008 1996 6105 2063 7528 4506 2008 2052 6464 6133 1996 3896 1997 12520 2076 1996 2558 1997 3668 3169 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2241 2006 3319 1997 1996 4506 7528 3141 2000 1996 13308 6258 4722 2015 2565 12520 2968 2565 1010 1996 2136 2071 2025 16519 2008 1996 6105 2063 7528 4506 2008 2052 6464 6133 1996 3896 1997 12520 2076 1996 2558 1997 3668 3169 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] it also defined an adverse trend as a negative change in performance that knowledge , experience , and judgment indicated an adverse impact on safety or reliability , or because a relative large number of performance problems pointed to more significant future problems . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] it also defined an adverse trend as a negative change in performance that knowledge , experience , and judgment indicated an adverse impact on safety or reliability , or because a relative large number of performance problems pointed to more significant future problems . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2009 2036 4225 2019 15316 9874 2004 1037 4997 2689 1999 2836 2008 3716 1010 3325 1010 1998 8689 5393 2019 15316 4254 2006 3808 2030 15258 1010 2030 2138 1037 5816 2312 2193 1997 2836 3471 4197 2000 2062 3278 2925 3471 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2009 2036 4225 2019 15316 9874 2004 1037 4997 2689 1999 2836 2008 3716 1010 3325 1010 1998 8689 5393 2019 15316 4254 2006 3808 2030 15258 1010 2030 2138 1037 5816 2312 2193 1997 2836 3471 4197 2000 2062 3278 2925 3471 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the license ##e investigated these concerns and determined that this alternate sample point was not adequate in that it did not meet the intent of technical specification 3 . 3 . 3 . 1 , action 28 , which required that grab samples be taken every 8 hours . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the license ##e investigated these concerns and determined that this alternate sample point was not adequate in that it did not meet the intent of technical specification 3 . 3 . 3 . 1 , action 28 , which required that grab samples be taken every 8 hours . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6105 2063 10847 2122 5936 1998 4340 2008 2023 6585 7099 2391 2001 2025 11706 1999 2008 2009 2106 2025 3113 1996 7848 1997 4087 12827 1017 1012 1017 1012 1017 1012 1015 1010 2895 2654 1010 2029 3223 2008 6723 8168 2022 2579 2296 1022 2847 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6105 2063 10847 2122 5936 1998 4340 2008 2023 6585 7099 2391 2001 2025 11706 1999 2008 2009 2106 2025 3113 1996 7848 1997 4087 12827 1017 1012 1017 1012 1017 1012 1015 1010 2895 2654 1010 2029 3223 2008 6723 8168 2022 2579 2296 1022 2847 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the team determined that the license ##e had not evaluated whether the groundwater had become aggressive to below grade and buried portions of concrete structures since approval of the license renewal application . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the team determined that the license ##e had not evaluated whether the groundwater had become aggressive to below grade and buried portions of concrete structures since approval of the license renewal application . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 2136 4340 2008 1996 6105 2063 2018 2025 16330 3251 1996 22761 2018 2468 9376 2000 2917 3694 1998 3950 8810 1997 5509 5090 2144 6226 1997 1996 6105 14524 4646 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 2136 4340 2008 1996 6105 2063 2018 2025 16330 3251 1996 22761 2018 2468 9376 2000 2917 3694 1998 3950 8810 1997 5509 5090 2144 6226 1997 1996 6105 14524 4646 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 2 (id = 2)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"pj5GHNzCZQ6m","colab_type":"code","outputId":"e0034d72-2bce-47b5-d137-8fc5c19f4fa2","executionInfo":{"status":"ok","timestamp":1584407213660,"user_tz":420,"elapsed":896,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["#Example on first observation in the training set\n","print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n","print(\"-\"*30)\n","print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n","print(\"-\"*30)\n","print(\"Input IDs : \", train_features[0].input_ids)\n","print(\"-\"*30)\n","print(\"Input Masks : \", train_features[0].input_mask)\n","print(\"-\"*30)\n","print(\"Segment IDs : \", train_features[0].segment_ids)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sentence :  Contrary to the above, on October, 27, 2011, the NRC identified that the licensee failed to ensure that, during post-fire safe shutdown, Unit 1 and Unit 2 reactor coolant process variables would be maintained within those predicted for a loss of normal ac power.\n","------------------------------\n","Tokens :  ['contrary', 'to', 'the', 'above', ',', 'on', 'october', ',', '27', ',', '2011', ',', 'the', 'nr', '##c', 'identified', 'that', 'the', 'license', '##e', 'failed', 'to', 'ensure', 'that', ',', 'during', 'post', '-', 'fire', 'safe', 'shut', '##down', ',', 'unit', '1', 'and', 'unit', '2', 'reactor', 'cool', '##ant', 'process', 'variables', 'would', 'be', 'maintained', 'within', 'those', 'predicted', 'for', 'a', 'loss', 'of', 'normal', 'ac', 'power', '.']\n","------------------------------\n","Input IDs :  [101, 10043, 2000, 1996, 2682, 1010, 2006, 2255, 1010, 2676, 1010, 2249, 1010, 1996, 17212, 2278, 4453, 2008, 1996, 6105, 2063, 3478, 2000, 5676, 2008, 1010, 2076, 2695, 1011, 2543, 3647, 3844, 7698, 1010, 3131, 1015, 1998, 3131, 1016, 13308, 4658, 4630, 2832, 10857, 2052, 2022, 5224, 2306, 2216, 10173, 2005, 1037, 3279, 1997, 3671, 9353, 2373, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","------------------------------\n","Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","------------------------------\n","Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mCW3_44hzHxp","colab_type":"text"},"source":["## 3. Creating a Multi-Class Classifier Model"]},{"cell_type":"code","metadata":{"id":"bEO8W_ZqZTnN","colab_type":"code","colab":{}},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOii_VgvZdT5","colab_type":"code","colab":{}},"source":["#A function that adapts our model to work for training, evaluation, and prediction.\n","\n","# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        \n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","            }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhjEFghXZhyP","colab_type":"code","colab":{}},"source":["# Compute train and warmup steps from batch size\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 40.0\n","# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 300\n","SAVE_SUMMARY_STEPS = 100\n","\n","# Compute train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqb8ufUqZoWA","colab_type":"code","outputId":"760252f3-a150-48ae-8755-1159edfabda4","executionInfo":{"status":"ok","timestamp":1584407229560,"user_tz":420,"elapsed":885,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["#Initializing the model and the estimator\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/DS_Lab/Models/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff6786a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/DS_Lab/Models/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff6786a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yP1mygXhZsuX","colab_type":"code","colab":{}},"source":["# Create an input function for training. drop_remainder = True for using TPUs.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)\n","\n","# Create an input function for validating. drop_remainder = True for using TPUs.\n","val_input_fn = run_classifier.input_fn_builder(\n","    features=val_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K1h09fYfzVEl","colab_type":"text"},"source":["## 4. Training & Evaluating"]},{"cell_type":"code","metadata":{"id":"9KfVXQv-ZyXP","colab_type":"code","outputId":"e58e2147-b94a-4214-f4b1-675b97215ee2","executionInfo":{"status":"ok","timestamp":1584407336592,"user_tz":420,"elapsed":101133,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-26-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-26-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 1.7943234, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 1.7943234, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 57 into /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 57 into /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.09933025.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.09933025.\n"],"name":"stderr"},{"output_type":"stream","text":["Training took time  0:01:40.271083\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B633itRFZ_y8","colab_type":"code","outputId":"c71115a1-0d8c-426d-d6b7-d32116c766a7","executionInfo":{"status":"ok","timestamp":1584407490079,"user_tz":420,"elapsed":20177,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":464}},"source":["#Evaluating the model with Validation set\n","val_acc = estimator.evaluate(input_fn=val_input_fn, steps=None)['eval_accuracy']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-03-17T01:11:19Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-03-17T01:11:19Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt-57\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt-57\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-03-17-01:11:26\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-03-17-01:11:26\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 57: eval_accuracy = 0.75, false_negatives = 0.0, false_positives = 0.0, global_step = 57, loss = 0.8077462, true_negatives = 0.0, true_positives = 12.0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 57: eval_accuracy = 0.75, false_negatives = 0.0, false_positives = 0.0, global_step = 57, loss = 0.8077462, true_negatives = 0.0, true_positives = 12.0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 57: /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt-57\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 57: /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt-57\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"SDchTwIRzkOB","colab_type":"text"},"source":["## 5. Predicting For Test Set"]},{"cell_type":"code","metadata":{"id":"bwQiEarfgAY8","colab_type":"code","colab":{}},"source":["\"\"\"{'T':0, 'P': 1, 'O': 2, 'D': 3, 'H': 4} 3\"\"\"\n","\n","# A method to get predictions\n","def getPrediction(df_test):\n","\n","  in_sentences = list(df_test['text'])\n","  #A list to map the actual labels to the predictions\n","  labels = ['T', 'P', 'O', 'D', 'H']\n","\n","  #Transforming the test data into BERT accepted form\n","  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n","  \n","  #Creating input features for Test data\n","  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","  #Predicting the classes \n","  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n","  predictions = estimator.predict(predict_input_fn)\n","  pred = [labels[prediction['labels']] for prediction in predictions]\n","  df_test['Y'] = [labels[Y] for Y in list(df_test['Y'])]\n","  df_test['Predicted_Values'] = pred\n","\n","  total_matching = sum(df_test['Y'] == pred)\n","  total = len(pred)\n","  acc = total_matching/total\n","  print('accuracy = ',acc)\n","  return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ULPS4lPgnyU","colab_type":"code","outputId":"34647dd5-03df-4a12-f236-bbc57a2e95f4","executionInfo":{"status":"ok","timestamp":1584407503614,"user_tz":420,"elapsed":6064,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["test_evals = getPrediction(df_test)\n","test_acc = test_evals"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 12\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 12\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] specifically , by failing to establish a prevent ##ive maintenance strategy for fire safe shut ##down transfer / isolation switches , ex ##elo ##n did not ensure that the local control circuits for several 4 ##k ##v breakers would be isolated from the effects of fire damage . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] specifically , by failing to establish a prevent ##ive maintenance strategy for fire safe shut ##down transfer / isolation switches , ex ##elo ##n did not ensure that the local control circuits for several 4 ##k ##v breakers would be isolated from the effects of fire damage . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4919 1010 2011 7989 2000 5323 1037 4652 3512 6032 5656 2005 2543 3647 3844 7698 4651 1013 12477 15924 1010 4654 18349 2078 2106 2025 5676 2008 1996 2334 2491 13782 2005 2195 1018 2243 2615 24742 2052 2022 7275 2013 1996 3896 1997 2543 4053 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4919 1010 2011 7989 2000 5323 1037 4652 3512 6032 5656 2005 2543 3647 3844 7698 4651 1013 12477 15924 1010 4654 18349 2078 2106 2025 5676 2008 1996 2334 2491 13782 2005 2195 1018 2243 2615 24742 2052 2022 7275 2013 1996 3896 1997 2543 4053 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] analysis : the failure to establish a prevent ##ive maintenance strategy for safe shut ##down transfer / isolation switches was a performance deficiency that was reasonably within ex ##elo ##n ' s ability to fore ##see and prevent . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] analysis : the failure to establish a prevent ##ive maintenance strategy for safe shut ##down transfer / isolation switches was a performance deficiency that was reasonably within ex ##elo ##n ' s ability to fore ##see and prevent . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4106 1024 1996 4945 2000 5323 1037 4652 3512 6032 5656 2005 3647 3844 7698 4651 1013 12477 15924 2001 1037 2836 18888 2008 2001 16286 2306 4654 18349 2078 1005 1055 3754 2000 18921 19763 1998 4652 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4106 1024 1996 4945 2000 5323 1037 4652 3512 6032 5656 2005 3647 3844 7698 4651 1013 12477 15924 2001 1037 2836 18888 2008 2001 16286 2306 4654 18349 2078 1005 1055 3754 2000 18921 19763 1998 4652 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the failure to follow procedures was a violation of technical specification 6 . 8 . 1 . a . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the failure to follow procedures was a violation of technical specification 6 . 8 . 1 . a . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 4945 2000 3582 8853 2001 1037 11371 1997 4087 12827 1020 1012 1022 1012 1015 1012 1037 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 4945 2000 3582 8853 2001 1037 11371 1997 4087 12827 1020 1012 1022 1012 1015 1012 1037 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] failure to pre ##cl ##ude repetitive failures of the train a class 1 ##e air condition ##er , a significant condition adverse to quality , is a performance deficiency . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] failure to pre ##cl ##ude repetitive failures of the train a class 1 ##e air condition ##er , a significant condition adverse to quality , is a performance deficiency . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4945 2000 3653 20464 12672 23563 15428 1997 1996 3345 1037 2465 1015 2063 2250 4650 2121 1010 1037 3278 4650 15316 2000 3737 1010 2003 1037 2836 18888 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4945 2000 3653 20464 12672 23563 15428 1997 1996 3345 1037 2465 1015 2063 2250 4650 2121 1010 1037 3278 4650 15316 2000 3737 1010 2003 1037 2836 18888 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the license ##e did not ensure complete , accurate and up - to - date design documentation , procedures , and work packages , and correct labeling of components . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the license ##e did not ensure complete , accurate and up - to - date design documentation , procedures , and work packages , and correct labeling of components . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6105 2063 2106 2025 5676 3143 1010 8321 1998 2039 1011 2000 1011 3058 2640 12653 1010 8853 1010 1998 2147 14555 1010 1998 6149 28847 1997 6177 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 6105 2063 2106 2025 5676 3143 1010 8321 1998 2039 1011 2000 1011 3058 2640 12653 1010 8853 1010 1998 2147 14555 1010 1998 6149 28847 1997 6177 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt-57\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/DS_Lab/Models/model.ckpt-57\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["accuracy =  0.6666666666666666\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"k5HykG_UEEt9","colab_type":"text"},"source":["## 6. Saving the results"]},{"cell_type":"code","metadata":{"id":"M0vCyP2rg3bk","colab_type":"code","outputId":"8e4b34c1-03ab-45f8-aae8-66a14181f674","executionInfo":{"status":"ok","timestamp":1584407610479,"user_tz":420,"elapsed":903,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["df_test.to_csv('Sally_Frenard_Agree.csv', index = False)\n","df_test.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>end_pos</th>\n","      <th>file</th>\n","      <th>line</th>\n","      <th>start_pos</th>\n","      <th>text</th>\n","      <th>Y</th>\n","      <th>Predicted_Values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>66</th>\n","      <td>415</td>\n","      <td>ML13182A476.txt</td>\n","      <td>44</td>\n","      <td>162</td>\n","      <td>Specifically, by failing to establish a preven...</td>\n","      <td>O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>232</th>\n","      <td>1983</td>\n","      <td>ML13182A476.txt</td>\n","      <td>80</td>\n","      <td>1772</td>\n","      <td>Analysis: The failure to establish a preventiv...</td>\n","      <td>O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1225</th>\n","      <td>1518</td>\n","      <td>ML071350662.txt</td>\n","      <td>167</td>\n","      <td>1434</td>\n","      <td>The failure to follow procedures was a violati...</td>\n","      <td>T</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1646</th>\n","      <td>3010</td>\n","      <td>ML14041A484.txt</td>\n","      <td>35</td>\n","      <td>2857</td>\n","      <td>Failure to preclude repetitive failures of the...</td>\n","      <td>O</td>\n","      <td>T</td>\n","    </tr>\n","    <tr>\n","      <th>1653</th>\n","      <td>977</td>\n","      <td>ML14041A484.txt</td>\n","      <td>39</td>\n","      <td>827</td>\n","      <td>The licensee did not ensure complete, accurate...</td>\n","      <td>O</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      end_pos             file  ...  Y  Predicted_Values\n","66        415  ML13182A476.txt  ...  O                 O\n","232      1983  ML13182A476.txt  ...  O                 O\n","1225     1518  ML071350662.txt  ...  T                 O\n","1646     3010  ML14041A484.txt  ...  O                 T\n","1653      977  ML14041A484.txt  ...  O                 O\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"rlmAr-UrmPnm","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix\n","\n","pred_labels = list(set(df_test['Y']))\n","\n","conf_mat = confusion_matrix(df_test['Y'], df_test['Predicted_Values'], pred_labels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yed3QYCVOL2i","colab_type":"code","outputId":"04b45150-20f9-4062-e027-dd6a0b735966","executionInfo":{"status":"ok","timestamp":1584407591592,"user_tz":420,"elapsed":866,"user":{"displayName":"Shefali Anand","photoUrl":"","userId":"07758119825372166379"}},"colab":{"base_uri":"https://localhost:8080/","height":76}},"source":["final_result = pd.DataFrame(columns = ['Coder','Train_Accuracy','Val_Accuracy','Test_Accuracy','#TestData','#AllData'])\n","list = []\n","list.append('Sally_Frenard_Agree')\n","final_result['Coder'] = list\n","list = []\n","list.append(val_acc)\n","final_result['Val_Accuracy'] = list\n","list = []\n","list.append(test_acc)\n","final_result['Test_Accuracy'] = list\n","list = []\n","list.append(len(df_test['text']))\n","final_result['#TestData'] = list\n","list = []\n","list.append(len(df['text']))\n","final_result['#AllData'] = list\n","list = []\n","list.append(pred_labels)\n","final_result['Classes'] = list\n","list = []\n","list.append(conf_mat)\n","final_result['Confusion Matrix'] = list\n","final_result"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Coder</th>\n","      <th>Train_Accuracy</th>\n","      <th>Val_Accuracy</th>\n","      <th>Test_Accuracy</th>\n","      <th>#TestData</th>\n","      <th>#AllData</th>\n","      <th>Classes</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sally_Frenard_Agree</td>\n","      <td>NaN</td>\n","      <td>0.75</td>\n","      <td>0.666667</td>\n","      <td>12</td>\n","      <td>70</td>\n","      <td>[O, T, P]</td>\n","      <td>[[7, 1, 0], [2, 1, 0], [1, 0, 0]]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Coder  ...                   Confusion Matrix\n","0  Sally_Frenard_Agree  ...  [[7, 1, 0], [2, 1, 0], [1, 0, 0]]\n","\n","[1 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"Qq-PvIpisZyh","colab_type":"code","colab":{}},"source":["if not tf.io.gfile.exists(\"/GD/My Drive/Colab Notebooks/DS_Lab/Results/Final_Results.csv\"):\n","  final_result.to_csv(\"/GD/My Drive/Colab Notebooks/DS_Lab/Results/Final_Results.csv\", header=True)\n","else:\n","  final_result.to_csv(\"/GD/My Drive/Colab Notebooks/DS_Lab/Results/Final_Results.csv\", mode='a', header=False)"],"execution_count":0,"outputs":[]}]}